{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping posts from r/conspiracy\n",
    "\n",
    "Extraction of all the posts resent in r/conspiracy, with title, content and url.\n",
    "First of all we need to import praw and access reddit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "reddit = praw.Reddit(client_id = \"\", client_secret= \"\", user_agent= \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now access the subreddit, extract all the posts in it and check which other subreddit reposted that posts and how much:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "post_list=list()\n",
    "subreddit_list = list()\n",
    "conspiracy_dict=dict()\n",
    "\n",
    "#put the subreddit already passed here\n",
    "id_to_avoid = [\"conspiracy\"]\n",
    "\n",
    "for i in reddit.subreddit(\"conspiracy\").hot(limit=5000): #recupera i 5000 post top di conspiracy\n",
    "    post_list.append((i.title, i.score, i.url)) #recupera titolo, numero di upvote + il permalink\n",
    "\n",
    "\n",
    "for post in post_list:\n",
    "    for repost in reddit.subreddit('all').search('url:'+post[2]): #trova quando il post Ã¨ stato citato\n",
    "        if repost.subreddit_id not in id_to_avoid:\n",
    "            \n",
    "            subreddit_url = str(repost.subreddit)\n",
    "            subreddit_url = \"https://www.reddit.com/r/\" + subreddit_url\n",
    "            if subreddit_url in conspiracy_dict.keys():\n",
    "                conspiracy_dict[subreddit_url][0].append(\"https://www.reddit.com\"+repost.permalink)\n",
    "                conspiracy_dict[subreddit_url][1][0] +=1\n",
    "            else:\n",
    "                conspiracy_dict[subreddit_url]=[[],[1]]\n",
    "                conspiracy_dict[subreddit_url][0].append(\"https://www.reddit.com\"+repost.permalink)\n",
    "                \n",
    "\n",
    "\n",
    "df = pd.DataFrame(conspiracy_dict)\n",
    "df.to_csv(r'results/conspiracy_top_url.csv',index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can also estract the posts with the same permalink:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_list=list()\n",
    "subreddit_list = list()\n",
    "conspiracy_dict=dict()\n",
    "\n",
    "#put the subreddit already passed here\n",
    "id_to_avoid = [\"conspiracy\"]\n",
    "\n",
    "for i in reddit.subreddit(\"conspiracy\").top(limit=5000):\n",
    "    post_list.append((i.title, i.score, \"https://www.reddit.com\"+i.permalink))\n",
    "\n",
    "\n",
    "for post in post_list:\n",
    "    for repost in reddit.subreddit('all').search('url:'+post[2]):\n",
    "        if repost.subreddit_id not in id_to_avoid:\n",
    "            subreddit_url = str(repost.subreddit)\n",
    "            subreddit_url = \"https://www.reddit.com/r/\" + subreddit_url\n",
    "            if subreddit_url in conspiracy_dict.keys():\n",
    "                conspiracy_dict[subreddit_url][0].append(\"https://www.reddit.com\"+repost.permalink)\n",
    "                conspiracy_dict[subreddit_url][1][0] +=1\n",
    "            else:\n",
    "                conspiracy_dict[subreddit_url]=[[], [1]]\n",
    "                conspiracy_dict[subreddit_url][0].append(\"https://www.reddit.com\"+repost.permalink)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(conspiracy_dict)\n",
    "df.to_csv(r'results/conspiracy_top.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we have the CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('results/conspiracy_hot.csv')\n",
    "id_to_analyse = []\n",
    "for column in df1.columns:\n",
    "    value = df1[column][1][1:-1]\n",
    "    if int(value) >= 5:\n",
    "        ind = column.index('/r/')\n",
    "        id = column[ind+3:]\n",
    "        id_to_analyse.append(id)\n",
    "\n",
    "for subreddit in id_to_analyse:\n",
    "    post_list=list()\n",
    "    subreddit_list = list()\n",
    "    conspiracy_dict=dict() \n",
    "    for i in reddit.subreddit(subreddit).top(limit=5000):\n",
    "        post_list.append((i.title, i.score, \"https://www.reddit.com\"+i.permalink))\n",
    "\n",
    "\n",
    "    for post in post_list:\n",
    "        for repost in reddit.subreddit('all').search('url:'+post[2]):\n",
    "            if repost.subreddit_id != subreddit: #cosa facciamo?\n",
    "                subreddit_url = str(repost.subreddit)\n",
    "                subreddit_url = \"https://www.reddit.com/r/\" + subreddit_url\n",
    "                if subreddit_url in conspiracy_dict.keys():\n",
    "                    conspiracy_dict[subreddit_url][0].append(\"https://www.reddit.com\"+repost.permalink)\n",
    "                    conspiracy_dict[subreddit_url][1][0] +=1\n",
    "                else:\n",
    "                    conspiracy_dict[subreddit_url]=[[],[1]]\n",
    "                    conspiracy_dict[subreddit_url][0].append(\"https://www.reddit.com\"+repost.permalink)\n",
    "    df = pd.DataFrame(conspiracy_dict)\n",
    "    df.to_csv(r'results/'+subreddit+'.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "69eb92836b941e979072a76c7fcfffe5419cca933cedd02cfafbdfca1a93358c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
