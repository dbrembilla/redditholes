{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping posts from r/conspiracy\n",
    "\n",
    "Extraction of all the posts resent in r/conspiracy, with title, content and url.\n",
    "First of all we need to import praw and access reddit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "from praw.models import MoreComments\n",
    "import pandas as pd\n",
    "reddit = praw.Reddit(client_id = \"\", client_secret= \"\", user_agent= \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now access the subreddit, extract all the posts url in it and check which other subreddit reposted that posts and how much:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "post_list=list()\n",
    "subreddit_list = list()\n",
    "conspiracy_dict=dict()\n",
    "\n",
    "for i in reddit.subreddit(\"conspiracy\").top(limit=5000): #recupera i 5000 post top di conspiracy\n",
    "    post_list.append((i.title, i.score, i.url)) #recupera titolo, numero di upvote + il permalink\n",
    "\n",
    "\n",
    "for post in post_list:\n",
    "    for repost in reddit.subreddit('all').search('url:'+post[2]): #trova quando il post Ã¨ stato citato\n",
    "        subreddit_url = str(repost.subreddit)\n",
    "        subreddit_url = \"https://www.reddit.com/r/\" + subreddit_url\n",
    "        if subreddit_url in conspiracy_dict.keys():\n",
    "            conspiracy_dict[subreddit_url][0].append(\"https://www.reddit.com\"+repost.permalink)\n",
    "            conspiracy_dict[subreddit_url][1][0] +=1\n",
    "        else:\n",
    "            conspiracy_dict[subreddit_url]=[[],[1]]\n",
    "            conspiracy_dict[subreddit_url][0].append(\"https://www.reddit.com\"+repost.permalink)\n",
    "            \n",
    "                \n",
    "\n",
    "\n",
    "df = pd.DataFrame(conspiracy_dict)\n",
    "df.to_csv(r'results/conspiracy_data/conspiracy_top_url.csv',index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the network\n",
    "Now we need to create the network of subreddits involved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_in_dir(dir):\n",
    "    for filename in os.listdir(dir):\n",
    "        f = os.path.join(dir, filename)\n",
    "        if os.path.isfile(f) and f[-4:] == \".csv\":\n",
    "            yield f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "datasets= [file for file in get_all_in_dir(\"results/1st_level\")]\n",
    "datasets.extend(file for file in get_all_in_dir(\"results/2nd_level\"))\n",
    "\n",
    "network_list = list()\n",
    "\n",
    "for subr in datasets:\n",
    "        #print(f'now opening {subr}')\n",
    "        try:\n",
    "                df1 = pd.read_csv(subr)\n",
    "        except:\n",
    "                pass\n",
    "        try:\n",
    "                df1 = pd.read_csv(subr, encoding='utf8')\n",
    "        except:\n",
    "                print(f'unable to open {subr}')\n",
    "                continue\n",
    "        sub_name=subr[subr.find(\"\\\\\")+1:-4]\n",
    "        for column in df1.columns:\n",
    "                if column [:7] != \"Unnamed\":\n",
    "                        col_name = column[column.find(\"/r/\")+3:]\n",
    "                        try:\n",
    "                                network_list.append((sub_name, col_name, df1[column][1]))\n",
    "                        except Exception as E:\n",
    "                                print(E) \n",
    "                else: \n",
    "                        continue\n",
    "print(network_list)\n",
    "\n",
    "'''with open('Network.csv', 'w') as f:\n",
    "      \n",
    "    # using csv.writer method from CSV package\n",
    "    write = csv.writer(f)\n",
    "      \n",
    "    write.writerow([\"Source\", \"Target\", \"Weight\"])\n",
    "    write.writerows(network_list)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking for subnetworks in the original csvs\n",
    "Now that we have divided the main network in subnetworks we can llok for them in the original files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_in_dir(dir):\n",
    "    for filename in os.listdir(dir):\n",
    "        f = os.path.join(dir, filename)\n",
    "        if os.path.isfile(f) and f[-4:] == \".csv\":\n",
    "            yield f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "datasets= [file for file in get_all_in_dir(\"results/1st_level\")]\n",
    "datasets.extend(file for file in get_all_in_dir(\"results/2nd_level\"))\n",
    "\n",
    "networks=[file for file in get_all_in_dir(\"results/subnetworks\")]\n",
    "\n",
    "for net in networks:\n",
    "        try:\n",
    "                df_network = pd.read_csv(net)\n",
    "        except:\n",
    "                pass\n",
    "        try:\n",
    "                df_network = pd.read_csv(net, encoding='utf8')\n",
    "        except:\n",
    "                print(f'unable to open {subr}')\n",
    "                continue\n",
    "        network_name=net[net.find(\"\\\\\")+1:-4]\n",
    "        for subr in datasets:\n",
    "                #print(f'now opening {subr}')\n",
    "                try:\n",
    "                        df_dataset = pd.read_csv(subr)\n",
    "                except:\n",
    "                        pass\n",
    "                try:\n",
    "                        df_dataset = pd.read_csv(subr, encoding='utf8')\n",
    "                except:\n",
    "                        print(f'unable to open {subr}')\n",
    "                        continue\n",
    "                sub_name=subr[subr.find(\"\\\\\")+1:-4]\n",
    "                for column in df_dataset.columns:\n",
    "                        if column [:7] != \"Unnamed\":\n",
    "                                col_name = column[column.find(\"/r/\")+3:]\n",
    "                                for index, row in df_network.iterrows():\n",
    "                                        if (col_name == row[\"Source\"] and sub_name == row[\"Target\"]) or (col_name == row[\"Target\"] and sub_name == row[\"Source\"]):\n",
    "                                                try:\n",
    "                                                        network_list.append((sub_name, col_name, df_dataset[column][1],df_dataset[column][0]))\n",
    "                                                except Exception as E:\n",
    "                                                        print(E) \n",
    "                                        else: \n",
    "                                                continue\n",
    "        \n",
    "        \n",
    "        with open(network_name+'.csv', 'w') as f:\n",
    "                # using csv.writer method from CSV package\n",
    "                write = csv.writer(f)\n",
    "                \n",
    "                write.writerow([\"Source\", \"Target\", \"Weight\",\"Comments\"])\n",
    "                write.writerows(network_list)\n",
    "                \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n most connected subreddits\n",
    "def takeSecond(elem):\n",
    "    return int(elem[2])\n",
    "\n",
    "sorted(network_list, key=takeSecond, reverse=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "69eb92836b941e979072a76c7fcfffe5419cca933cedd02cfafbdfca1a93358c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
