{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2022 Giorgia Sampò <giorgia.sampo@studio.unibo.it>, Davide Brembilla <davide.brembilla@studio.unibo.it>\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RedditHoles - A study in  internet Rabbit Holes\n",
    "\n",
    "## An introduction to Reddit\n",
    "\n",
    "Reddit is a social media platform organised in communities, rather than individual connections. This makes the experience on the platform quite different from other Social Networks and closer, in a way, to the one of forums.  \n",
    "This is the source material for the website [RedditHoles](https://dbrembilla.github.io/redditholes/). We advise you to take a look at it before examining our code. If you find issues, please update an issue on Github.\n",
    "\n",
    "### u_User / u/User\n",
    "A user (also called redditor, usually referred as “u/” followed by the username) can make a post (also called a submission); posts (also called submissions) can be links, videos, pictures, polls or text. The OP (Original Poster) as well as other users can comment and vote (either upvote or downvote) the post if they find it interesting (so it’s not exactly like like/dislike features of other Social Networks). Finally, users can give posts awards by paying for reddit coins; these recognise the contributions of a post or comment. There are hundreds of these, from a generic gold or silver award to some following internet lingo, such as the “F” award (used ironically to ‘pay respect’). \n",
    "\n",
    "Users can mark their posts as spoilers and multiple types of flairs and markings such as OC (Original Content), Spoilers, +18 and so on. Some subreddits might have rules for posting. \n",
    "\n",
    "Users can be humans or bots. Bots have multiple uses, from auto moderation, to answering with quotes from movies and books, waving flags to other utilities and fun uses. \n",
    "#### The average redditor\n",
    "\n",
    "Reddit users, according to [data from the site itself](https://www.redditinc.com/advertising/audience), are more than 50 million with more than 100 thousand communities. They are mostly male (56%) and have between 18 and 34 year old (58%). \n",
    "\n",
    "### r/Subreddits\n",
    "\n",
    "Reddit is structured in subreddits, communities that group in various ways the interested users. Subreddits can vary from cute pets, to political parties, to recipe advice. Subreddits are usually referred to as “r/” followed by the name of the subreddits (in our case, we will study “r/conspiracy” and related subreddits). \n",
    "\n",
    "Subreddits can vary significantly. They can have rules for posting, different levels of moderation and bot acceptance, all depending from the nature of the subreddit. Rules of subreddits can have different nature; some subreddits may require the content of a post to be marked, some require sources to be linked, some can have no rules at all. This ambiguity makes Reddit a much more decentralised and open Social Network in which some of the cut down on fake news and trolls which happened on sites such as Facebook or Twitter has not yet happened at the same level. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing Reddit Data\n",
    "In order to access data from the Reddit API, we used the [`praw` python library](https://github.com/praw-dev/praw). \n",
    "In order to use that, we need:\n",
    "- a Reddit account.\n",
    "- a Reddit app ([here](https://www.reddit.com/prefs/apps) you can create one). You will find the client id under the app name once you create it, as well as the client secret and the user agent, which is your app name.\n",
    "\n",
    "Once we have those, we can access Reddit by creating a Reddit instance in praw (it is also possible to access as a user by adding username and account if you want to use it in write mode, meaning you can post from the terminal if you so choose)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install praw\n",
    "#!pip install pandas\n",
    "import praw\n",
    "reddit = praw.Reddit(client_id = \"my_client\", client_secret= \"my_secret\", user_agent= \"my_user_agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can access information about subreddits, posts and users. As an example, we can access the top 5 posts of all time on Reddit, with the information about the author and the upvote ratio and date (in UTC format):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in reddit.subreddit('all').top(limit=5): #this will print the top posts all time\n",
    "    print(i.title + ' Author: ' + i.author.name +  ' Link: https://www.reddit.com' + i.permalink + ' Subreddit: r/' + i.subreddit.display_name + ' Upvote Ratio: ' + str(i.upvote_ratio) + ' Date (UTC Format): '+str(i.created_utc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Reddit, starting from r/conspiracy\n",
    "\n",
    "Our objective is to watch how a piece of news or a post is shared between different subreddits. While most social network would measure shares of a post, Reddit is built in a way that if a link is shared in the platform, it is possible to retrieve how much the original link is shared through subreddits. As an example, if an image from imgur is shared, we can use its url to search for the same object on Reddit.\n",
    "This happens because, for the most part, Reddit is used to comment news and multimedia in communities, which often present a common worldview (e.g. subbreddits made by people with same political views).\n",
    "We started with the [r/conspiracy](https://www.reddit.com/r/conspiracy/)'s posts, in particular the top 5000 posts all time. We opted for the top posts all time because the other types of ranking are time-bound and we wanted to watch the overall transmission of posts.\n",
    "Please keep in mind that your results may be different than ours; we scraped Reddit between February and April 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "post_list=list()\n",
    "subreddit_list = list()\n",
    "conspiracy_dict=dict()\n",
    "\n",
    "for i in reddit.subreddit(\"conspiracy\").top(limit=5000): \n",
    "    post_list.append(i.url) # This may seem counterintuitive, but in praw's terms this is the original link of the resource inside the post.\n",
    "\n",
    "\n",
    "for post in post_list:\n",
    "    for repost in reddit.subreddit('all').search('url:'+post): # This function searches for the original post's element\n",
    "        subreddit_url = str(repost.subreddit)\n",
    "        if subreddit_url =='conspiracy':\n",
    "            continue\n",
    "        subreddit_url = \"https://www.reddit.com/r/\" + subreddit_url\n",
    "        if subreddit_url in conspiracy_dict.keys():\n",
    "            conspiracy_dict[subreddit_url][0].append(\"https://www.reddit.com\"+repost.permalink)\n",
    "            conspiracy_dict[subreddit_url][1][0] +=1\n",
    "        else:\n",
    "            conspiracy_dict[subreddit_url]=[[],[1]]\n",
    "            conspiracy_dict[subreddit_url][0].append(\"https://www.reddit.com\"+repost.permalink)\n",
    "            \n",
    "                \n",
    "\n",
    "\n",
    "df = pd.DataFrame(conspiracy_dict)\n",
    "df.to_csv(r'results/conspiracy_data/conspiracy.csv',index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We realised after the fact that this method also got the reposts inside the same subreddit. After manually cleaning the csv in this instance, we proceeded to remove this problem in the following steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a network of subreddits\n",
    "\n",
    "After scraping r/conspiracy, we moved to the neighbouring subreddits. What this will do is creating a network of shared posts between subreddits.\n",
    "\n",
    "First we need to look at all the files in the directory. We built this function to easily get all the csv files easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_in_dir(dir):\n",
    "    for filename in os.listdir(dir):\n",
    "        f = os.path.join(dir, filename)\n",
    "        if os.path.isfile(f) and f[-4:] == \".csv\":\n",
    "            yield f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can scrape the other subreddits that had more than 5 posts in common with r/conspiracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('results/conspiracy_data/conspiracy.csv')\n",
    "id_to_analyse = []\n",
    " # We iterate over the csv columns to see all the informations in them, selecting only the subreddits with more than 5 posts in common\n",
    "for column in df1.columns:\n",
    "    value = df1[column][1][1:-1]\n",
    "    if int(value) >= 5:\n",
    "        ind = column.index('/r/')\n",
    "        id = column[ind+3:]\n",
    "        id_to_analyse.append(id)\n",
    "        \n",
    "\n",
    "for subreddit in id_to_analyse:\n",
    "    post_list=list()\n",
    "    subreddit_list = list()\n",
    "    conspiracy_dict=dict() \n",
    "    for i in reddit.subreddit(subreddit).top(limit=5000):\n",
    "        post_list.append((i.title, i.score, i.url))\n",
    "\n",
    "\n",
    "\n",
    "    for post in post_list:\n",
    "        for repost in reddit.subreddit('all').search('url:'+post[2]):\n",
    "            if repost.subreddit_id != \"t5_\"+reddit.subreddit(subreddit).id: # avoid reposts\n",
    "                subreddit_url = str(repost.subreddit)\n",
    "                subreddit_url = \"https://www.reddit.com/r/\" + subreddit_url\n",
    "                if subreddit_url in conspiracy_dict.keys():\n",
    "                    conspiracy_dict[subreddit_url][0].append(\"https://www.reddit.com\"+repost.permalink)\n",
    "                    conspiracy_dict[subreddit_url][1][0] +=1\n",
    "                else:\n",
    "                    conspiracy_dict[subreddit_url]=[[],[1]]\n",
    "                    conspiracy_dict[subreddit_url][0].append(\"https://www.reddit.com\"+repost.permalink)\n",
    "    df = pd.DataFrame(conspiracy_dict)\n",
    "    df.to_csv(r'results/1st_level/'+subreddit+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We repeat the cycle one more time, but this time with just the top 500 posts, in order to speed up the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "top_comments_list = dict()\n",
    "to_scan = [file for file in get_all_in_dir(\"results/1st_level_2\")]\n",
    "to_avoid= [file.split('\\\\')[1] for file in get_all_in_dir(\"results/1st_level\")]\n",
    "# To separate the load of scraping between two computers and not repeat scraping for existing subreddits, we divided the 1st level \\\\\n",
    "# in two separate folders.\n",
    "# to_avoid.extend(file.split('\\\\')[1] for file in get_all_in_dir(\"results/1st_level_2\"))\n",
    "# to_avoid.extend(file.split('\\\\')[1] for file in get_all_in_dir(\"results/2nd_level\"))\n",
    "\n",
    "for subr in to_scan:\n",
    "        id_to_analyse = []\n",
    "        print(f'now opening {subr}')\n",
    "        try:\n",
    "                df1 = pd.read_csv(subr)\n",
    "        except:\n",
    "                pass\n",
    "        try:\n",
    "                df1 = pd.read_csv(subr, encoding='utf8')\n",
    "        except:\n",
    "                print(f'unable to open {subr}')\n",
    "                continue\n",
    "        for column in df1.columns:\n",
    "                try: \n",
    "                        value = df1[column][1][1:-1]\n",
    "                except:\n",
    "                        continue\n",
    "                if int(value) >= 5:\n",
    "                        ind = column.index('/r/')\n",
    "                        id = column[ind+3:]\n",
    "                        if not id + '.csv' in to_avoid:\n",
    "                                try:\n",
    "                                        post_list=list()\n",
    "                                        subreddit_list = list()\n",
    "                                        conspiracy_dict=dict() \n",
    "                                        for i in reddit.subreddit(id).top(limit=500):\n",
    "                                                post_list.append((i.title, i.score, i.url))\n",
    "\n",
    "                                        for post in post_list:\n",
    "                                                for repost in reddit.subreddit('all').search('url:'+post[2]):\n",
    "                                                        if repost.subreddit_id != \"t5_\"+reddit.subreddit(id).id: #cosa facciamo?\n",
    "                                                                subreddit_url = str(repost.subreddit)\n",
    "                                                                subreddit_url = \"https://www.reddit.com/r/\" + subreddit_url\n",
    "                                                        else:\n",
    "                                                                continue\n",
    "                                                        if subreddit_url in conspiracy_dict.keys():\n",
    "                                                                conspiracy_dict[subreddit_url][0].append(\"https://www.reddit.com\"+repost.permalink)\n",
    "                                                                conspiracy_dict[subreddit_url][1][0] +=1\n",
    "                                                        else:\n",
    "                                                                conspiracy_dict[subreddit_url]=[[],[1]]\n",
    "                                                                conspiracy_dict[subreddit_url][0].append(\"https://www.reddit.com\"+repost.permalink)\n",
    "                                        \n",
    "                                        df = pd.DataFrame(conspiracy_dict)\n",
    "                                        df.to_csv(r'results/2nd_level/'+id+'.csv')\n",
    "                                        with open(\"results/2nd_level/done_2.txt\",'a', encoding = \"utf-8\") as text_note:\n",
    "                                                text_note.write(id + \"\\n\")\n",
    "                                                text_note.close()\n",
    "                                        \n",
    "                                except Exception as E:\n",
    "                                        print(E)\n",
    "                                        with open(\"results/2nd_level/error_2.txt\",'a', encoding = \"utf-8\") as text_note:\n",
    "                                                text_note.write(id + \"\\n\")\n",
    "                                                text_note.close()\n",
    "                                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data\n",
    "In order to perform more efficiently the operations of data representation we decided two perform two operations:\n",
    "1. We turned the number of crossposts into integers.\n",
    "2. We removed subreddits with less than 5 posts in common.\n",
    "We did this in order to have cleaner and easier to use data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing parentheses and connections with less than 5 reposts\n",
    "import pandas as pd\n",
    "datasets= [file for file in get_all_in_dir(\"results/1st_level\")]\n",
    "datasets.extend(file for file in get_all_in_dir(\"results/1st_level_2\"))\n",
    "datasets.extend(file for file in get_all_in_dir(\"results/2nd_level\"))\n",
    "datasets.extend(\"results/conspiracy_data/conspiracy_top_url.csv\")\n",
    "\n",
    "for file in datasets:\n",
    "    try:\n",
    "        df = pd.read_csv(file, sep=',', on_bad_lines='skip', encoding='utf8')\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        df = pd.read_csv(file, on_bad_lines='skip', encoding='latin')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(file, 'has problems in formatting')\n",
    "        continue\n",
    "    for col in df.columns:\n",
    "        if \"u/\" in col or 'u_' in col: #Sometimes users end up in the columns. Remove them. \n",
    "            df.drop(col, inplace=True, axis=1)\n",
    "        else:\n",
    "            try:\n",
    "                \n",
    "               if isinstance(df[col][1], str): \n",
    "                    try:\n",
    "                        df[col][1]=int(df[col][1][1:-1])\n",
    "                    except:\n",
    "                        continue\n",
    "                    if df[col][1]<5:\n",
    "                        df.drop(col, inplace=True, axis=1)\n",
    "            except:\n",
    "                df.drop(col, inplace=True, axis=1)\n",
    "    df.to_csv(file, encoding=\"utf8\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the data from Reddit, we can build a network of shared posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Network of crossposts\n",
    "By using Gephi, we plotted the network of crosspost. By doing this, we found some communities of subreddits that present a significant number of crossposts.\n",
    "1. <b>Crypto, Tech and other news</b>, with a part dedicated to tech (BitcoinAll, Mistifront, Libertarian, Technews and brprogramming) and another about politics and conspiracies (conspiracy, politics...).\n",
    "2. <b>MetaReddit</b>, subreddits that share a meta-reddit approach (e.g. bots collecting stories from everywhere or comments about reddit), that are also very interlinked with generalist subreddits (such as r/pics). Among these are mistyfront, SubredditNN, Blackout2015. This is very intelinked with tech and general politics.  \n",
    "3. <b>Politics/News</b> with various news and political subreddits, from either party or with no party affiliation, but also with a significant conspiracy news subgroups. Among these are anythingGoesNews, ConspiracyII, Coronavirus, infrasociology\n",
    "4. <b>Leftist Politics</b> centred around WayOfTheBern, LateStageCapitalism, SocialismAndVeganism, but also TrueReddit.\n",
    "5. <b>Bernie Sanders</b> - Started from StillSandersForPresident, WayOfTheBern, RealBlueMidterm (central to other minor subreddits) A significant group of subreddits all sharing the topic of popularising the figure of Bernie Sanders. The main gateways seem to be NEwYorkSanders,FLoridaforSanders ad CaliforniaFOrSanders.\n",
    "6. <b>Conservative/Libertarian</b> subreddits from the right and alt-right, with Conservative, Libertarian, Descent into tyranny but also  news sources such as Worldpolitics and alternative news subreddits such as Censorship \n",
    "7. <b>Science and Pseudoscience</b>, subreddits discussing both scientific news(environment, AutoNewspaper), views of the future(futurology) but also pseudoscience (ScienceUncensored, DebateVaccines)\n",
    "8. <b>Information</b> a subnetwork connected both to general information subreddits (todayilearned) and classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the network\n",
    "datasets= [file for file in get_all_in_dir(\"results/1st_level\")]\n",
    "datasets.extend(file for file in get_all_in_dir(\"results/1st_level_2\"))\n",
    "datasets.extend(file for file in get_all_in_dir(\"results/2nd_level\"))\n",
    "\n",
    "network_list = list()\n",
    "\n",
    "for subr in datasets:\n",
    "        #print(f'now opening {subr}')\n",
    "        try:\n",
    "                df1 = pd.read_csv(subr)\n",
    "        except:\n",
    "                pass\n",
    "        try:\n",
    "                df1 = pd.read_csv(subr, encoding='utf8')\n",
    "        except:\n",
    "                print(f'unable to open {subr}')\n",
    "                continue\n",
    "        sub_name=subr[subr.find(\"\\\\\")+1:-4]\n",
    "        for column in df1.columns:\n",
    "                try: \n",
    "                        value = column\n",
    "                except:\n",
    "                        continue\n",
    "                if column [:7] != \"Unnamed\":\n",
    "                        col_name = column[column.find(\"/r/\")+3:]\n",
    "                        try:\n",
    "                                network_list.append((sub_name, col_name, df1[column][1]))\n",
    "                        except Exception as E:\n",
    "                                print(E) \n",
    "                else: \n",
    "                        continue\n",
    "print(network_list)\n",
    "\n",
    "'''' with open('Network.csv', 'w') as f:\n",
    "      \n",
    "    # using csv.writer method from CSV package\n",
    "    write = csv.writer(f)\n",
    "      \n",
    "    write.writerow([\"Source\", \"Target\", \"Weight\"])\n",
    "    write.writerows(network_list)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing the comments\n",
    "A part of our inquiry involves the kind of language that redditors use on the website in response to posts. In order to this, we employed two techniques that allow us to find out the nature of a text: Topic Modelling and Sentiment Analysis\n",
    "\n",
    "### Topic modelling\n",
    "Topic modelling is a machine learning technique that tries to predict the distribution of abstract topics in a text, and thus reveal the hidden semantic structures within it. In particular, we used Latent Dirichlet Allocation (LDA) method. We adapted the method used in [here](https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/#1introduction).\n",
    "The libraries used are <code>[nltk](https://www.nltk.org/), [gensim](https://github.com/RaRe-Technologies/gensim/), [spacy](https://spacy.io/), [pyLDAvis](https://pyldavis.readthedocs.io/en/latest/readme.html)</code>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the number of comments can be particularly big, we used this code snippet to get a random sample from bigger comment sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def iterSample(iterable, samplesize):\n",
    "    results = []\n",
    "    for i, v in enumerate(iterable):\n",
    "        r = random.randint(0, i)\n",
    "        if r < samplesize:\n",
    "            if i < samplesize:\n",
    "                results.insert(r, v) # add first samplesize items in random order\n",
    "            else:\n",
    "                results[r] = v # at a decreasing rate, replace random items\n",
    "\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we import the dataset and the comments from the posts in common between subreddits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "to_scan= [file for file in get_all_in_dir(\"results/subnetworks\")]\n",
    "for subreddit in to_scan:\n",
    "        comment_dict = dict()\n",
    "        print('Opening', subreddit)\n",
    "        try: \n",
    "\n",
    "                df = pd.read_csv(subreddit, encoding='utf8', on_bad_lines='skip')\n",
    "                \n",
    "                if os.path.isfile('comments_'+subreddit.split('\\\\')[1]):\n",
    "                        start = (pd.read_csv('comments_'+subreddit.split('\\\\')[1])['Source'].iloc[-1], pd.read_csv('comments_'+subreddit.split('\\\\')[1])['Target'].iloc[-1])\n",
    "                        start= int(df.loc[(df['Source'] == start[0]) & (df['Target'] == start[1])].index[0])\n",
    "                        if start >= len(df):\n",
    "                                continue        \n",
    "                        df = df[start+1:].dropna()\n",
    "        except Exception as e:\n",
    "               print('error',e,subreddit)\n",
    "               continue\n",
    "                \n",
    "        for row in df.to_dict(orient='records'):\n",
    "                if isinstance(row['Source'], float) or isinstance(row['Target'],float):\n",
    "                        continue\n",
    "                if 'https' in row['Source'] or 'https' in row['Target']:\n",
    "                        continue\n",
    "                try:\n",
    "                        list_post= row['Posts'][1:-1].split(',')\n",
    "                except Exception as e:\n",
    "                        continue\n",
    "                result = ''\n",
    "                num = 0\n",
    "                for post_url in list_post:\n",
    "                        if post_url == 0:\n",
    "                                continue\n",
    "                        post_url = post_url.replace(' ','')\n",
    "                        #tmp =  re.sub(\"\\[\\]\\'\", \"\", post_url) NON FUNZIONA E NON CAPISCO PERCHé\n",
    "                        if post_url[1:-1] in comment_dict.keys():\n",
    "                                result += comment_dict[post_url[1:-1]][0]\n",
    "                                num += comment_dict[post_url[1:-1]][1]\n",
    "                                continue\n",
    "                        try:\n",
    "                                post = reddit.submission(url=post_url[1:-1])\n",
    "                                try:\n",
    "                                        #This allows up to 1 reply to each post.\n",
    "                                        post.comments.replace_more(limit=1)\n",
    "                                except Exception as e:\n",
    "                                        print(e)\n",
    "                                        print(f'{post}s comments was not accessible')\n",
    "                                        continue\n",
    "                                num += len(post.comments)\n",
    "                                this_comment = ''\n",
    "                                if num > 500:\n",
    "                                        for comment in iterSample(post.comments, 500):\n",
    "                                                try:\n",
    "                                                        this_comment += comment.body\n",
    "                                                        for reply in comment.replies:\n",
    "                                                                this_comment+= reply.body\n",
    "                                                        this_comment=this_comment.replace(',','')\n",
    "                                                        this_comment=this_comment.replace('\\n','\\s')\n",
    "                                                except Exception as e:\n",
    "                                                        print(e)\n",
    "                                                        continue\n",
    "                                else:\n",
    "                                        for comment in post.comments:\n",
    "                                                try:\n",
    "                                                        this_comment += comment.body\n",
    "                                                        for reply in comment.replies:\n",
    "                                                                this_comment+= reply.body\n",
    "                                                        this_comment=this_comment.replace(',','')\n",
    "                                                        this_comment=this_comment.replace('\\n','\\s')\n",
    "\n",
    "                                                except Exception as e:\n",
    "                                                        print(e)\n",
    "                                                        continue\n",
    "                                comment_dict[post_url[1:-1]] = (this_comment,num)\n",
    "                                result += this_comment\n",
    "                        except Exception as e:\n",
    "                                print(e)\n",
    "                                print(post.permalink + ' is not accessible')\n",
    "                                continue                                         \n",
    "                res=pd.DataFrame.from_dict([{'Source':row['Source'], 'Target':row['Target'],'NumberComments': num,'Comments':result}])\n",
    "                if os.path.isfile('comments_'+subreddit.split('\\\\')[1]):\n",
    "                        res.to_csv('comments_'+subreddit.split('\\\\')[1],  encoding='utf8', mode='a', header=False)\n",
    "                else:\n",
    "                        res.to_csv('comments_'+subreddit.split('\\\\')[1],  encoding='utf8')\n",
    "                        \n",
    "        print(subreddit, ' is finished')\n",
    "                        \n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now perform the \n",
    "### Topic modeling\n",
    "First we need to define the functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nltk\n",
    "#!pip install gensim\n",
    "#!pip install spacy\n",
    "#!pip install pyLDAvis\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['re', 'edit','http\\_np', 'autotldr\\_pm', 'autotldr\\_comment', 'version\\_tl', 'comment\\_fm', 'thing', 'com']) \n",
    "\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as genmodels  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "#python -m spacy download en_core_web_sm\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now print a csv for each subnetwork identified, containing the topic modeling of the common posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_scan = [file for file in get_all_in_dir('comments')] #inserire iterazione su tutti i csv\n",
    "to_scan.sort(reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_model(corpus, id2word):\n",
    "    if corpus != [] and corpus != [[]] and corpus!=[[[]]]:\n",
    "        try:\n",
    "            # Build LDA model\n",
    "            lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                                    id2word=id2word,\n",
    "                                                    num_topics=5, \n",
    "                                                    random_state=100,\n",
    "                                                    update_every=1,\n",
    "                                                    chunksize=100,\n",
    "                                                    passes=10,\n",
    "                                                    alpha='symmetric',\n",
    "                                                    per_word_topics=True)\n",
    "\n",
    "            # Print the Keyword in the 10 topics\n",
    "            topics = {}\n",
    "            list_topics=lda_model.print_topics(num_words=5)\n",
    "            for topic in list_topics:\n",
    "                topics[topic[0]] = topic[1].split(\" + \")\n",
    "            out = pd.DataFrame(topics)\n",
    "            return out\n",
    "        except Exception as e:\n",
    "            return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "avoid=set()\n",
    "\n",
    "for file in to_scan:\n",
    "    if file in avoid:\n",
    "        continue\n",
    "    df = pd.read_csv(file, encoding = 'utf8')\n",
    "    if any(char.isdigit() for char in file):\n",
    "        filename = file.split('\\\\')[1]\n",
    "        filename = re.sub('\\d|\\.csv', '', filename)\n",
    "        for el in to_scan:\n",
    "            if filename in el:\n",
    "                avoid.add(el)\n",
    "                df = df.append(pd.read_csv(el, encoding=\"utf-8\", header=None))\n",
    "\n",
    "    df = df.astype(str)\n",
    "\n",
    "    comments = df[\"Comments\"]\n",
    "    \n",
    "    # Remove new line characters\n",
    "    data = [re.sub('\\s+', ' ', sent) for sent in comments]\n",
    "\n",
    "    # Remove distracting single quotes\n",
    "    data = [re.sub(\"\\'\", \"\", sent) for sent in data]\n",
    "\n",
    "    # Tokenizing the text\n",
    "    data_words = list(sent_to_words(data))\n",
    "\n",
    "    # Build the bigram and trigram models\n",
    "    bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "    trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "\n",
    "    # Faster way to get a sentence clubbed as a trigram/bigram\n",
    "    bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "    trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "    # Remove Stop Words\n",
    "    data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "    # Form Bigrams\n",
    "    data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "    # Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "    # python3 -m spacy download en\n",
    "    nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "    \n",
    "    for i in range(len(data_words_bigrams)):\n",
    "        el=data_words_bigrams[i]\n",
    "        if len(el)>=100000:#avoid inputs larger than 1000000 by random sampling them\\\n",
    "            data_words_bigrams[i] = iterSample(el, 100000)\n",
    "            \n",
    "\n",
    "    # Do lemmatization keeping only noun, adj, vb, adv\n",
    "    data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "    # Create Dictionary\n",
    "    id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "    # Create Corpus\n",
    "    texts = data_lemmatized\n",
    "\n",
    "    # Term Document Frequency\n",
    "    corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "    # Human readable format of corpus (term-frequency)\n",
    "    [[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]\n",
    "\n",
    "    out = topic_model(corpus, id2word)\n",
    "    out.to_csv(\"topic_modeling_\"+ file.split(\"\\\\\")[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WE can now plot graphs using the topic models obtained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_plot = [file for file in get_all_in_dir('topics')] #inserire iterazione su tutti i csv\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib, random\n",
    "\n",
    "hex_colors_dic = {}\n",
    "rgb_colors_dic = {}\n",
    "hex_colors_only = []\n",
    "for name, hex in matplotlib.colors.cnames.items():\n",
    "    hex_colors_only.append(hex)\n",
    "    hex_colors_dic[name] = hex\n",
    "    rgb_colors_dic[name] = matplotlib.colors.to_rgb(hex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\n    Invalid value of type 'builtins.str' received for the 'annotations' property of layout\n        Received value: 'True'\n\n    The 'annotations' property is a tuple of instances of\n    Annotation that may be specified as:\n      - A list or tuple of instances of plotly.graph_objs.layout.Annotation\n      - A list or tuple of dicts of string/value properties that\n        will be passed to the Annotation constructor\n\n        Supported dict properties:\n            \n            align\n                Sets the horizontal alignment of the `text`\n                within the box. Has an effect only if `text`\n                spans two or more lines (i.e. `text` contains\n                one or more <br> HTML tags) or if an explicit\n                width is set to override the text width.\n            arrowcolor\n                Sets the color of the annotation arrow.\n            arrowhead\n                Sets the end annotation arrow head style.\n            arrowside\n                Sets the annotation arrow head position.\n            arrowsize\n                Sets the size of the end annotation arrow head,\n                relative to `arrowwidth`. A value of 1\n                (default) gives a head about 3x as wide as the\n                line.\n            arrowwidth\n                Sets the width (in px) of annotation arrow\n                line.\n            ax\n                Sets the x component of the arrow tail about\n                the arrow head. If `axref` is `pixel`, a\n                positive (negative) component corresponds to an\n                arrow pointing from right to left (left to\n                right). If `axref` is not `pixel` and is\n                exactly the same as `xref`, this is an absolute\n                value on that axis, like `x`, specified in the\n                same coordinates as `xref`.\n            axref\n                Indicates in what coordinates the tail of the\n                annotation (ax,ay) is specified. If set to a ax\n                axis id (e.g. \"ax\" or \"ax2\"), the `ax` position\n                refers to a ax coordinate. If set to \"paper\",\n                the `ax` position refers to the distance from\n                the left of the plotting area in normalized\n                coordinates where 0 (1) corresponds to the left\n                (right). If set to a ax axis ID followed by\n                \"domain\" (separated by a space), the position\n                behaves like for \"paper\", but refers to the\n                distance in fractions of the domain length from\n                the left of the domain of that axis: e.g., *ax2\n                domain* refers to the domain of the second ax\n                axis and a ax position of 0.5 refers to the\n                point between the left and the right of the\n                domain of the second ax axis. In order for\n                absolute positioning of the arrow to work,\n                \"axref\" must be exactly the same as \"xref\",\n                otherwise \"axref\" will revert to \"pixel\"\n                (explained next). For relative positioning,\n                \"axref\" can be set to \"pixel\", in which case\n                the \"ax\" value is specified in pixels relative\n                to \"x\". Absolute positioning is useful for\n                trendline annotations which should continue to\n                indicate the correct trend when zoomed.\n                Relative positioning is useful for specifying\n                the text offset for an annotated point.\n            ay\n                Sets the y component of the arrow tail about\n                the arrow head. If `ayref` is `pixel`, a\n                positive (negative) component corresponds to an\n                arrow pointing from bottom to top (top to\n                bottom). If `ayref` is not `pixel` and is\n                exactly the same as `yref`, this is an absolute\n                value on that axis, like `y`, specified in the\n                same coordinates as `yref`.\n            ayref\n                Indicates in what coordinates the tail of the\n                annotation (ax,ay) is specified. If set to a ay\n                axis id (e.g. \"ay\" or \"ay2\"), the `ay` position\n                refers to a ay coordinate. If set to \"paper\",\n                the `ay` position refers to the distance from\n                the bottom of the plotting area in normalized\n                coordinates where 0 (1) corresponds to the\n                bottom (top). If set to a ay axis ID followed\n                by \"domain\" (separated by a space), the\n                position behaves like for \"paper\", but refers\n                to the distance in fractions of the domain\n                length from the bottom of the domain of that\n                axis: e.g., *ay2 domain* refers to the domain\n                of the second ay  axis and a ay position of 0.5\n                refers to the point between the bottom and the\n                top of the domain of the second ay axis. In\n                order for absolute positioning of the arrow to\n                work, \"ayref\" must be exactly the same as\n                \"yref\", otherwise \"ayref\" will revert to\n                \"pixel\" (explained next). For relative\n                positioning, \"ayref\" can be set to \"pixel\", in\n                which case the \"ay\" value is specified in\n                pixels relative to \"y\". Absolute positioning is\n                useful for trendline annotations which should\n                continue to indicate the correct trend when\n                zoomed. Relative positioning is useful for\n                specifying the text offset for an annotated\n                point.\n            bgcolor\n                Sets the background color of the annotation.\n            bordercolor\n                Sets the color of the border enclosing the\n                annotation `text`.\n            borderpad\n                Sets the padding (in px) between the `text` and\n                the enclosing border.\n            borderwidth\n                Sets the width (in px) of the border enclosing\n                the annotation `text`.\n            captureevents\n                Determines whether the annotation text box\n                captures mouse move and click events, or allows\n                those events to pass through to data points in\n                the plot that may be behind the annotation. By\n                default `captureevents` is False unless\n                `hovertext` is provided. If you use the event\n                `plotly_clickannotation` without `hovertext`\n                you must explicitly enable `captureevents`.\n            clicktoshow\n                Makes this annotation respond to clicks on the\n                plot. If you click a data point that exactly\n                matches the `x` and `y` values of this\n                annotation, and it is hidden (visible: false),\n                it will appear. In \"onoff\" mode, you must click\n                the same point again to make it disappear, so\n                if you click multiple points, you can show\n                multiple annotations. In \"onout\" mode, a click\n                anywhere else in the plot (on another data\n                point or not) will hide this annotation. If you\n                need to show/hide this annotation in response\n                to different `x` or `y` values, you can set\n                `xclick` and/or `yclick`. This is useful for\n                example to label the side of a bar. To label\n                markers though, `standoff` is preferred over\n                `xclick` and `yclick`.\n            font\n                Sets the annotation text font.\n            height\n                Sets an explicit height for the text box. null\n                (default) lets the text set the box height.\n                Taller text will be clipped.\n            hoverlabel\n                :class:`plotly.graph_objects.layout.annotation.\n                Hoverlabel` instance or dict with compatible\n                properties\n            hovertext\n                Sets text to appear when hovering over this\n                annotation. If omitted or blank, no hover label\n                will appear.\n            name\n                When used in a template, named items are\n                created in the output figure in addition to any\n                items the figure already has in this array. You\n                can modify these items in the output figure by\n                making your own item with `templateitemname`\n                matching this `name` alongside your\n                modifications (including `visible: false` or\n                `enabled: false` to hide it). Has no effect\n                outside of a template.\n            opacity\n                Sets the opacity of the annotation (text +\n                arrow).\n            showarrow\n                Determines whether or not the annotation is\n                drawn with an arrow. If True, `text` is placed\n                near the arrow's tail. If False, `text` lines\n                up with the `x` and `y` provided.\n            standoff\n                Sets a distance, in pixels, to move the end\n                arrowhead away from the position it is pointing\n                at, for example to point at the edge of a\n                marker independent of zoom. Note that this\n                shortens the arrow from the `ax` / `ay` vector,\n                in contrast to `xshift` / `yshift` which moves\n                everything by this amount.\n            startarrowhead\n                Sets the start annotation arrow head style.\n            startarrowsize\n                Sets the size of the start annotation arrow\n                head, relative to `arrowwidth`. A value of 1\n                (default) gives a head about 3x as wide as the\n                line.\n            startstandoff\n                Sets a distance, in pixels, to move the start\n                arrowhead away from the position it is pointing\n                at, for example to point at the edge of a\n                marker independent of zoom. Note that this\n                shortens the arrow from the `ax` / `ay` vector,\n                in contrast to `xshift` / `yshift` which moves\n                everything by this amount.\n            templateitemname\n                Used to refer to a named item in this array in\n                the template. Named items from the template\n                will be created even without a matching item in\n                the input figure, but you can modify one by\n                making an item with `templateitemname` matching\n                its `name`, alongside your modifications\n                (including `visible: false` or `enabled: false`\n                to hide it). If there is no template or no\n                matching item, this item will be hidden unless\n                you explicitly show it with `visible: true`.\n            text\n                Sets the text associated with this annotation.\n                Plotly uses a subset of HTML tags to do things\n                like newline (<br>), bold (<b></b>), italics\n                (<i></i>), hyperlinks (<a href='...'></a>).\n                Tags <em>, <sup>, <sub> <span> are also\n                supported.\n            textangle\n                Sets the angle at which the `text` is drawn\n                with respect to the horizontal.\n            valign\n                Sets the vertical alignment of the `text`\n                within the box. Has an effect only if an\n                explicit height is set to override the text\n                height.\n            visible\n                Determines whether or not this annotation is\n                visible.\n            width\n                Sets an explicit width for the text box. null\n                (default) lets the text set the box width.\n                Wider text will be clipped. There is no\n                automatic wrapping; use <br> to start a new\n                line.\n            x\n                Sets the annotation's x position. If the axis\n                `type` is \"log\", then you must take the log of\n                your desired range. If the axis `type` is\n                \"date\", it should be date strings, like date\n                data, though Date objects and unix milliseconds\n                will be accepted and converted to strings. If\n                the axis `type` is \"category\", it should be\n                numbers, using the scale where each category is\n                assigned a serial number from zero in the order\n                it appears.\n            xanchor\n                Sets the text box's horizontal position anchor\n                This anchor binds the `x` position to the\n                \"left\", \"center\" or \"right\" of the annotation.\n                For example, if `x` is set to 1, `xref` to\n                \"paper\" and `xanchor` to \"right\" then the\n                right-most portion of the annotation lines up\n                with the right-most edge of the plotting area.\n                If \"auto\", the anchor is equivalent to \"center\"\n                for data-referenced annotations or if there is\n                an arrow, whereas for paper-referenced with no\n                arrow, the anchor picked corresponds to the\n                closest side.\n            xclick\n                Toggle this annotation when clicking a data\n                point whose `x` value is `xclick` rather than\n                the annotation's `x` value.\n            xref\n                Sets the annotation's x coordinate axis. If set\n                to a x axis id (e.g. \"x\" or \"x2\"), the `x`\n                position refers to a x coordinate. If set to\n                \"paper\", the `x` position refers to the\n                distance from the left of the plotting area in\n                normalized coordinates where 0 (1) corresponds\n                to the left (right). If set to a x axis ID\n                followed by \"domain\" (separated by a space),\n                the position behaves like for \"paper\", but\n                refers to the distance in fractions of the\n                domain length from the left of the domain of\n                that axis: e.g., *x2 domain* refers to the\n                domain of the second x  axis and a x position\n                of 0.5 refers to the point between the left and\n                the right of the domain of the second x axis.\n            xshift\n                Shifts the position of the whole annotation and\n                arrow to the right (positive) or left\n                (negative) by this many pixels.\n            y\n                Sets the annotation's y position. If the axis\n                `type` is \"log\", then you must take the log of\n                your desired range. If the axis `type` is\n                \"date\", it should be date strings, like date\n                data, though Date objects and unix milliseconds\n                will be accepted and converted to strings. If\n                the axis `type` is \"category\", it should be\n                numbers, using the scale where each category is\n                assigned a serial number from zero in the order\n                it appears.\n            yanchor\n                Sets the text box's vertical position anchor\n                This anchor binds the `y` position to the\n                \"top\", \"middle\" or \"bottom\" of the annotation.\n                For example, if `y` is set to 1, `yref` to\n                \"paper\" and `yanchor` to \"top\" then the top-\n                most portion of the annotation lines up with\n                the top-most edge of the plotting area. If\n                \"auto\", the anchor is equivalent to \"middle\"\n                for data-referenced annotations or if there is\n                an arrow, whereas for paper-referenced with no\n                arrow, the anchor picked corresponds to the\n                closest side.\n            yclick\n                Toggle this annotation when clicking a data\n                point whose `y` value is `yclick` rather than\n                the annotation's `y` value.\n            yref\n                Sets the annotation's y coordinate axis. If set\n                to a y axis id (e.g. \"y\" or \"y2\"), the `y`\n                position refers to a y coordinate. If set to\n                \"paper\", the `y` position refers to the\n                distance from the bottom of the plotting area\n                in normalized coordinates where 0 (1)\n                corresponds to the bottom (top). If set to a y\n                axis ID followed by \"domain\" (separated by a\n                space), the position behaves like for \"paper\",\n                but refers to the distance in fractions of the\n                domain length from the bottom of the domain of\n                that axis: e.g., *y2 domain* refers to the\n                domain of the second y  axis and a y position\n                of 0.5 refers to the point between the bottom\n                and the top of the domain of the second y axis.\n            yshift\n                Shifts the position of the whole annotation and\n                arrow up (positive) or down (negative) by this\n                many pixels.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12696/4163675977.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'word'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'importance'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     my_layout = go.Layout({\"title\": \"Main Topic\",\n\u001b[0m\u001b[0;32m     20\u001b[0m                        \u001b[1;34m\"yaxis\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"title\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"Importance\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m                        \u001b[1;34m\"xaxis\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"title\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"Word\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\plotly\\graph_objs\\_layout.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, arg, activeshape, annotations, annotationdefaults, autosize, autotypenumbers, bargap, bargroupgap, barmode, barnorm, boxgap, boxgroupgap, boxmode, calendar, clickmode, coloraxis, colorscale, colorway, computed, datarevision, dragmode, editrevision, extendfunnelareacolors, extendiciclecolors, extendpiecolors, extendsunburstcolors, extendtreemapcolors, font, funnelareacolorway, funnelgap, funnelgroupgap, funnelmode, geo, grid, height, hiddenlabels, hiddenlabelssrc, hidesources, hoverdistance, hoverlabel, hovermode, iciclecolorway, images, imagedefaults, legend, mapbox, margin, meta, metasrc, modebar, newshape, paper_bgcolor, piecolorway, plot_bgcolor, polar, scene, selectdirection, selectionrevision, separators, shapes, shapedefaults, showlegend, sliders, sliderdefaults, smith, spikedistance, sunburstcolorway, template, ternary, title, titlefont, transition, treemapcolorway, uirevision, uniformtext, updatemenus, updatemenudefaults, violingap, violingroupgap, violinmode, waterfallgap, waterfallgroupgap, waterfallmode, width, xaxis, yaxis, **kwargs)\u001b[0m\n\u001b[0;32m   5968\u001b[0m         \u001b[0m_v\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mannotations\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mannotations\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0m_v\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5969\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_v\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5970\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"annotations\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_v\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5971\u001b[0m         \u001b[0m_v\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"annotationdefaults\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5972\u001b[0m         \u001b[0m_v\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mannotationdefaults\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mannotationdefaults\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0m_v\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\plotly\\basedatatypes.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, prop, value)\u001b[0m\n\u001b[0;32m   5836\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmatch\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5837\u001b[0m             \u001b[1;31m# Set as ordinary property\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5838\u001b[1;33m             \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseLayoutHierarchyType\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5839\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5840\u001b[0m             \u001b[1;31m# Set as subplotid property\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\plotly\\basedatatypes.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, prop, value)\u001b[0m\n\u001b[0;32m   4830\u001b[0m                 \u001b[1;31m# ### Handle compound array property ###\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4831\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mCompoundArrayValidator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseDataValidator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4832\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_array_prop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4833\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4834\u001b[0m                 \u001b[1;31m# ### Handle simple property ###\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\plotly\\basedatatypes.py\u001b[0m in \u001b[0;36m_set_array_prop\u001b[1;34m(self, prop, val)\u001b[0m\n\u001b[0;32m   5311\u001b[0m         \u001b[1;31m# ------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5312\u001b[0m         \u001b[0mvalidator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_validator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5313\u001b[1;33m         \u001b[0mval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate_coerce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskip_invalid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_skip_invalid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5314\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5315\u001b[0m         \u001b[1;31m# Save deep copies of current and new states\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_plotly_utils\\basevalidators.py\u001b[0m in \u001b[0;36mvalidate_coerce\u001b[1;34m(self, v, skip_invalid)\u001b[0m\n\u001b[0;32m   2573\u001b[0m                 \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2574\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2575\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_invalid_val\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2577\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_plotly_utils\\basevalidators.py\u001b[0m in \u001b[0;36mraise_invalid_val\u001b[1;34m(self, v, inds)\u001b[0m\n\u001b[0;32m    287\u001b[0m                 \u001b[0mname\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m\"[\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    290\u001b[0m             \"\"\"\n\u001b[0;32m    291\u001b[0m     \u001b[0mInvalid\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtype\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mtyp\u001b[0m\u001b[1;33m}\u001b[0m \u001b[0mreceived\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[1;34m'{name}'\u001b[0m \u001b[0mproperty\u001b[0m \u001b[0mof\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mpname\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: \n    Invalid value of type 'builtins.str' received for the 'annotations' property of layout\n        Received value: 'True'\n\n    The 'annotations' property is a tuple of instances of\n    Annotation that may be specified as:\n      - A list or tuple of instances of plotly.graph_objs.layout.Annotation\n      - A list or tuple of dicts of string/value properties that\n        will be passed to the Annotation constructor\n\n        Supported dict properties:\n            \n            align\n                Sets the horizontal alignment of the `text`\n                within the box. Has an effect only if `text`\n                spans two or more lines (i.e. `text` contains\n                one or more <br> HTML tags) or if an explicit\n                width is set to override the text width.\n            arrowcolor\n                Sets the color of the annotation arrow.\n            arrowhead\n                Sets the end annotation arrow head style.\n            arrowside\n                Sets the annotation arrow head position.\n            arrowsize\n                Sets the size of the end annotation arrow head,\n                relative to `arrowwidth`. A value of 1\n                (default) gives a head about 3x as wide as the\n                line.\n            arrowwidth\n                Sets the width (in px) of annotation arrow\n                line.\n            ax\n                Sets the x component of the arrow tail about\n                the arrow head. If `axref` is `pixel`, a\n                positive (negative) component corresponds to an\n                arrow pointing from right to left (left to\n                right). If `axref` is not `pixel` and is\n                exactly the same as `xref`, this is an absolute\n                value on that axis, like `x`, specified in the\n                same coordinates as `xref`.\n            axref\n                Indicates in what coordinates the tail of the\n                annotation (ax,ay) is specified. If set to a ax\n                axis id (e.g. \"ax\" or \"ax2\"), the `ax` position\n                refers to a ax coordinate. If set to \"paper\",\n                the `ax` position refers to the distance from\n                the left of the plotting area in normalized\n                coordinates where 0 (1) corresponds to the left\n                (right). If set to a ax axis ID followed by\n                \"domain\" (separated by a space), the position\n                behaves like for \"paper\", but refers to the\n                distance in fractions of the domain length from\n                the left of the domain of that axis: e.g., *ax2\n                domain* refers to the domain of the second ax\n                axis and a ax position of 0.5 refers to the\n                point between the left and the right of the\n                domain of the second ax axis. In order for\n                absolute positioning of the arrow to work,\n                \"axref\" must be exactly the same as \"xref\",\n                otherwise \"axref\" will revert to \"pixel\"\n                (explained next). For relative positioning,\n                \"axref\" can be set to \"pixel\", in which case\n                the \"ax\" value is specified in pixels relative\n                to \"x\". Absolute positioning is useful for\n                trendline annotations which should continue to\n                indicate the correct trend when zoomed.\n                Relative positioning is useful for specifying\n                the text offset for an annotated point.\n            ay\n                Sets the y component of the arrow tail about\n                the arrow head. If `ayref` is `pixel`, a\n                positive (negative) component corresponds to an\n                arrow pointing from bottom to top (top to\n                bottom). If `ayref` is not `pixel` and is\n                exactly the same as `yref`, this is an absolute\n                value on that axis, like `y`, specified in the\n                same coordinates as `yref`.\n            ayref\n                Indicates in what coordinates the tail of the\n                annotation (ax,ay) is specified. If set to a ay\n                axis id (e.g. \"ay\" or \"ay2\"), the `ay` position\n                refers to a ay coordinate. If set to \"paper\",\n                the `ay` position refers to the distance from\n                the bottom of the plotting area in normalized\n                coordinates where 0 (1) corresponds to the\n                bottom (top). If set to a ay axis ID followed\n                by \"domain\" (separated by a space), the\n                position behaves like for \"paper\", but refers\n                to the distance in fractions of the domain\n                length from the bottom of the domain of that\n                axis: e.g., *ay2 domain* refers to the domain\n                of the second ay  axis and a ay position of 0.5\n                refers to the point between the bottom and the\n                top of the domain of the second ay axis. In\n                order for absolute positioning of the arrow to\n                work, \"ayref\" must be exactly the same as\n                \"yref\", otherwise \"ayref\" will revert to\n                \"pixel\" (explained next). For relative\n                positioning, \"ayref\" can be set to \"pixel\", in\n                which case the \"ay\" value is specified in\n                pixels relative to \"y\". Absolute positioning is\n                useful for trendline annotations which should\n                continue to indicate the correct trend when\n                zoomed. Relative positioning is useful for\n                specifying the text offset for an annotated\n                point.\n            bgcolor\n                Sets the background color of the annotation.\n            bordercolor\n                Sets the color of the border enclosing the\n                annotation `text`.\n            borderpad\n                Sets the padding (in px) between the `text` and\n                the enclosing border.\n            borderwidth\n                Sets the width (in px) of the border enclosing\n                the annotation `text`.\n            captureevents\n                Determines whether the annotation text box\n                captures mouse move and click events, or allows\n                those events to pass through to data points in\n                the plot that may be behind the annotation. By\n                default `captureevents` is False unless\n                `hovertext` is provided. If you use the event\n                `plotly_clickannotation` without `hovertext`\n                you must explicitly enable `captureevents`.\n            clicktoshow\n                Makes this annotation respond to clicks on the\n                plot. If you click a data point that exactly\n                matches the `x` and `y` values of this\n                annotation, and it is hidden (visible: false),\n                it will appear. In \"onoff\" mode, you must click\n                the same point again to make it disappear, so\n                if you click multiple points, you can show\n                multiple annotations. In \"onout\" mode, a click\n                anywhere else in the plot (on another data\n                point or not) will hide this annotation. If you\n                need to show/hide this annotation in response\n                to different `x` or `y` values, you can set\n                `xclick` and/or `yclick`. This is useful for\n                example to label the side of a bar. To label\n                markers though, `standoff` is preferred over\n                `xclick` and `yclick`.\n            font\n                Sets the annotation text font.\n            height\n                Sets an explicit height for the text box. null\n                (default) lets the text set the box height.\n                Taller text will be clipped.\n            hoverlabel\n                :class:`plotly.graph_objects.layout.annotation.\n                Hoverlabel` instance or dict with compatible\n                properties\n            hovertext\n                Sets text to appear when hovering over this\n                annotation. If omitted or blank, no hover label\n                will appear.\n            name\n                When used in a template, named items are\n                created in the output figure in addition to any\n                items the figure already has in this array. You\n                can modify these items in the output figure by\n                making your own item with `templateitemname`\n                matching this `name` alongside your\n                modifications (including `visible: false` or\n                `enabled: false` to hide it). Has no effect\n                outside of a template.\n            opacity\n                Sets the opacity of the annotation (text +\n                arrow).\n            showarrow\n                Determines whether or not the annotation is\n                drawn with an arrow. If True, `text` is placed\n                near the arrow's tail. If False, `text` lines\n                up with the `x` and `y` provided.\n            standoff\n                Sets a distance, in pixels, to move the end\n                arrowhead away from the position it is pointing\n                at, for example to point at the edge of a\n                marker independent of zoom. Note that this\n                shortens the arrow from the `ax` / `ay` vector,\n                in contrast to `xshift` / `yshift` which moves\n                everything by this amount.\n            startarrowhead\n                Sets the start annotation arrow head style.\n            startarrowsize\n                Sets the size of the start annotation arrow\n                head, relative to `arrowwidth`. A value of 1\n                (default) gives a head about 3x as wide as the\n                line.\n            startstandoff\n                Sets a distance, in pixels, to move the start\n                arrowhead away from the position it is pointing\n                at, for example to point at the edge of a\n                marker independent of zoom. Note that this\n                shortens the arrow from the `ax` / `ay` vector,\n                in contrast to `xshift` / `yshift` which moves\n                everything by this amount.\n            templateitemname\n                Used to refer to a named item in this array in\n                the template. Named items from the template\n                will be created even without a matching item in\n                the input figure, but you can modify one by\n                making an item with `templateitemname` matching\n                its `name`, alongside your modifications\n                (including `visible: false` or `enabled: false`\n                to hide it). If there is no template or no\n                matching item, this item will be hidden unless\n                you explicitly show it with `visible: true`.\n            text\n                Sets the text associated with this annotation.\n                Plotly uses a subset of HTML tags to do things\n                like newline (<br>), bold (<b></b>), italics\n                (<i></i>), hyperlinks (<a href='...'></a>).\n                Tags <em>, <sup>, <sub> <span> are also\n                supported.\n            textangle\n                Sets the angle at which the `text` is drawn\n                with respect to the horizontal.\n            valign\n                Sets the vertical alignment of the `text`\n                within the box. Has an effect only if an\n                explicit height is set to override the text\n                height.\n            visible\n                Determines whether or not this annotation is\n                visible.\n            width\n                Sets an explicit width for the text box. null\n                (default) lets the text set the box width.\n                Wider text will be clipped. There is no\n                automatic wrapping; use <br> to start a new\n                line.\n            x\n                Sets the annotation's x position. If the axis\n                `type` is \"log\", then you must take the log of\n                your desired range. If the axis `type` is\n                \"date\", it should be date strings, like date\n                data, though Date objects and unix milliseconds\n                will be accepted and converted to strings. If\n                the axis `type` is \"category\", it should be\n                numbers, using the scale where each category is\n                assigned a serial number from zero in the order\n                it appears.\n            xanchor\n                Sets the text box's horizontal position anchor\n                This anchor binds the `x` position to the\n                \"left\", \"center\" or \"right\" of the annotation.\n                For example, if `x` is set to 1, `xref` to\n                \"paper\" and `xanchor` to \"right\" then the\n                right-most portion of the annotation lines up\n                with the right-most edge of the plotting area.\n                If \"auto\", the anchor is equivalent to \"center\"\n                for data-referenced annotations or if there is\n                an arrow, whereas for paper-referenced with no\n                arrow, the anchor picked corresponds to the\n                closest side.\n            xclick\n                Toggle this annotation when clicking a data\n                point whose `x` value is `xclick` rather than\n                the annotation's `x` value.\n            xref\n                Sets the annotation's x coordinate axis. If set\n                to a x axis id (e.g. \"x\" or \"x2\"), the `x`\n                position refers to a x coordinate. If set to\n                \"paper\", the `x` position refers to the\n                distance from the left of the plotting area in\n                normalized coordinates where 0 (1) corresponds\n                to the left (right). If set to a x axis ID\n                followed by \"domain\" (separated by a space),\n                the position behaves like for \"paper\", but\n                refers to the distance in fractions of the\n                domain length from the left of the domain of\n                that axis: e.g., *x2 domain* refers to the\n                domain of the second x  axis and a x position\n                of 0.5 refers to the point between the left and\n                the right of the domain of the second x axis.\n            xshift\n                Shifts the position of the whole annotation and\n                arrow to the right (positive) or left\n                (negative) by this many pixels.\n            y\n                Sets the annotation's y position. If the axis\n                `type` is \"log\", then you must take the log of\n                your desired range. If the axis `type` is\n                \"date\", it should be date strings, like date\n                data, though Date objects and unix milliseconds\n                will be accepted and converted to strings. If\n                the axis `type` is \"category\", it should be\n                numbers, using the scale where each category is\n                assigned a serial number from zero in the order\n                it appears.\n            yanchor\n                Sets the text box's vertical position anchor\n                This anchor binds the `y` position to the\n                \"top\", \"middle\" or \"bottom\" of the annotation.\n                For example, if `y` is set to 1, `yref` to\n                \"paper\" and `yanchor` to \"top\" then the top-\n                most portion of the annotation lines up with\n                the top-most edge of the plotting area. If\n                \"auto\", the anchor is equivalent to \"middle\"\n                for data-referenced annotations or if there is\n                an arrow, whereas for paper-referenced with no\n                arrow, the anchor picked corresponds to the\n                closest side.\n            yclick\n                Toggle this annotation when clicking a data\n                point whose `y` value is `yclick` rather than\n                the annotation's `y` value.\n            yref\n                Sets the annotation's y coordinate axis. If set\n                to a y axis id (e.g. \"y\" or \"y2\"), the `y`\n                position refers to a y coordinate. If set to\n                \"paper\", the `y` position refers to the\n                distance from the bottom of the plotting area\n                in normalized coordinates where 0 (1)\n                corresponds to the bottom (top). If set to a y\n                axis ID followed by \"domain\" (separated by a\n                space), the position behaves like for \"paper\",\n                but refers to the distance in fractions of the\n                domain length from the bottom of the domain of\n                that axis: e.g., *y2 domain* refers to the\n                domain of the second y  axis and a y position\n                of 0.5 refers to the point between the bottom\n                and the top of the domain of the second y axis.\n            yshift\n                Shifts the position of the whole annotation and\n                arrow up (positive) or down (negative) by this\n                many pixels.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for file in to_plot:\n",
    "    topics = pd.read_csv(file, encoding=\"utf-8\")\n",
    "    topics = topics.drop(\"Unnamed: 0\", axis=1)\n",
    "    topics = topics.astype(str)\n",
    "    #print(topics.head())\n",
    "    path = file[:-4] + '_html.html'\n",
    "    out = []\n",
    "    \n",
    "    topics=topics[\"0\"]\n",
    "    for topic in topics:\n",
    "        topic = topic.replace('\"', \"\")\n",
    "        topic = topic.split('*')\n",
    "        weight = float(topic[0])\n",
    "        if weight<=0.000:\n",
    "            weight=0.001\n",
    "        out.append([topic[1], weight])\n",
    "\n",
    "    df = pd.DataFrame(out, columns=['word', 'importance']) \n",
    "    my_layout = go.Layout({\"title\": \"Main Topic\",\n",
    "                       \"yaxis\": {\"title\":\"Importance\"},\n",
    "                       \"xaxis\": {\"title\":\"Word\"},\n",
    "                       \"showlegend\": False}) \n",
    "    fig = px.bar(df, x='word', y = 'importance', range_color = random.choice(hex_colors_only), color='word')\n",
    "    fig.update_layout(my_layout)\n",
    "    fig.update_xaxes(tickangle = 45)\n",
    "    fig.write_html(path)\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wordclouds\n",
    "Another interesting visualization related to topics inside the text is the one of WordClouds or Tag Clouds.<br>\n",
    "After analyzing again the comments CSVs we can process them and understand word frequencies.<br>\n",
    "We can then proceed to properly represent them as word clouds, be the employment of <a href= \"https://amueller.github.io/word_cloud/\">Wordcloud</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from wordcloud import WordCloud\n",
    "to_tagcloud = [file for file in get_all_in_dir('comments')] #inserire iterazione su tutti i csv\n",
    "to_tagcloud.sort(reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multidict as multidict\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import re\n",
    "from PIL import Image\n",
    "from os import path\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def getFrequencyDictForText(sentence):\n",
    "    fullTermsDict = multidict.MultiDict()\n",
    "    tmpDict = {}\n",
    "\n",
    "    # making dict for counting frequencies\n",
    "    for text in sentence.split(\" \"):\n",
    "        if re.match('a|the|an|the|to|in|for|of|or|by|with|is|on|that|be|it\\.|http|thing|1|2|3|4|5|6|7|8|9|0|bot|than|;|&|tl;drs|-|>|out\\.', text):\n",
    "            continue\n",
    "        val = tmpDict.get(text, 0)\n",
    "        tmpDict[text.lower()] = val + 1\n",
    "    for key in tmpDict:\n",
    "        fullTermsDict.add(key, tmpDict[key])\n",
    "    return fullTermsDict\n",
    "\n",
    "\n",
    "def makeImage(text, path):\n",
    "    img_path = \"assets/img/alice_mask_1.png\"\n",
    "    alice_mask = np.array(Image.open(img_path))\n",
    "    \n",
    "\n",
    "    wc = WordCloud(background_color=None, mode=\"RGBA\", max_words=1000, mask=alice_mask)\n",
    "    # generate word cloud\n",
    "    wc.generate_from_frequencies(text)\n",
    "\n",
    "    # show\n",
    "    plt.imshow(wc, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(\"png_\"+path+'.png', format=\"png\", dpi=1200)\n",
    "    plt.show()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep TF-IDF Matrix for Word Clouds\n",
    "avoid=set()\n",
    "for file in to_tagcloud:\n",
    "    if file in avoid:\n",
    "        continue\n",
    "    df = pd.read_csv(file, encoding = 'utf8')\n",
    "    if any(char.isdigit() for char in file):\n",
    "        filename = file.split('\\\\')[1]\n",
    "        filename = re.sub('\\d|\\.csv', '', filename)\n",
    "        for el in to_tagcloud:\n",
    "            if filename in el:\n",
    "                avoid.add(el)\n",
    "                df = df.append(pd.read_csv(el, encoding=\"utf-8\", header=None))\n",
    "\n",
    "    df = df.astype(str)\n",
    "    text = df.sum()[\"Comments\"]\n",
    "    name_image=file.split(\"\\\\\")[1][:-4]\n",
    "    makeImage(getFrequencyDictForText(text), name_image)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis\n",
    "Sentiment analysis is the computational study of people's emotions expressed in text. In our case we used the popular VADER sentiment analyser, an analyser especially created for social networks (in particular, it was based off Twitter). The result of each comment's analysis will be a number between -1 and 1, depending on whether the comment is perceived as negative or positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_scan = [file for file in get_all_in_dir('comments')] #inserire iterazione su tutti i csv\n",
    "to_scan.sort(reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "avoid = set()\n",
    "for file in to_scan:\n",
    "    if file in avoid:\n",
    "        continue\n",
    "    df = pd.read_csv(file, encoding='utf8')\n",
    "    if any(char.isdigit() for char in file):\n",
    "        filename = file.split('\\\\')[1]\n",
    "        filename = re.sub('\\d|\\.csv', '', filename)\n",
    "        for el in to_scan:\n",
    "            if filename in el:\n",
    "                avoid.add(el)\n",
    "                before = len(df)\n",
    "                to_add = pd.read_csv(el, encoding='utf8', header=None)\n",
    "                df = df.append(to_add)\n",
    "                print(before < len(df))\n",
    "\n",
    "\n",
    "    heat = pd.DataFrame(columns = ['Index'])\n",
    "    targets = set(df['Target'])\n",
    "    to_add = {}\n",
    "    for column in targets:\n",
    "        if isinstance(column, float):\n",
    "            continue\n",
    "        if 'https' in column or '/' in column:\n",
    "            continue\n",
    "        with_target=df[df['Target']==column]\n",
    "        for row in with_target.to_dict(orient='records'):\n",
    "            to_add = {}\n",
    "            if row['Source'] not in heat['Index'].values:\n",
    "                to_add[column] = row['Comments']\n",
    "                to_add['Index'] = row[\"Source\"] \n",
    "                heat = heat.append(to_add, ignore_index=True)\n",
    "            else:\n",
    "                position = row['Source']\n",
    "                position = heat[heat[\"Index\"]==position].index\n",
    "                heat.at[position, column] = row['Comments']\n",
    "    heat.to_csv('heat\\\\heat_'+file.split('\\\\')[1], encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_sent = [file for file in get_all_in_dir('heat')]\n",
    "to_sent.sort(reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "#nltk.download(\"vader_lexicon\")\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sent = SentimentIntensityAnalyzer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for file in to_sent:\n",
    "    df = pd.read_csv(file, encoding = 'utf8').dropna(how='all')\n",
    "    df=df.set_index(\"Index\")\n",
    "    iterator = df.to_dict(orient='index')\n",
    "    for sub in iterator.keys():\n",
    "        for key in iterator[sub].keys():\n",
    "            if isinstance(iterator[sub][key], str):\n",
    "                df.at[sub, key] = sent.polarity_scores(iterator[sub][key])['compound']\n",
    "    df.to_csv('map' + file.split('\\\\')[1], encoding='utf8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import  matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "for data in get_all_in_dir('map'):\n",
    "    path = data.split('.')[0]+'_html.html'\n",
    "    df = pd.read_csv(data, encoding='utf8').drop('Unnamed: 0', axis=1)\n",
    "    df = df.set_index('Index')\n",
    "    df.index.rename('', inplace=True)\n",
    "    height = 800\n",
    "    if len(df.index) < 7:\n",
    "        height = 400\n",
    "    fig = px.imshow(df, height=height, width=1024, color_continuous_scale=['red','yellow','green'], aspect='auto',x=df.columns,y=df.index)\n",
    "    fig.update_xaxes(tickangle = 90)\n",
    "    fig.write_html(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Per plottare con pandas etc: inverti colonna, rendi int, droppa colonne inutili, and go."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[vedi qui](https://stackabuse.com/rotate-axis-labels-in-matplotlib/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "to_plot = get_all_in_dir('results')\n",
    "for i in to_plot:\n",
    "    df1 = pd.read_csv(i)\n",
    "    df2 = pd.read_csv(i)\n",
    "    path_src = i.split('.')[0]+'_src_html.html'\n",
    "    path_tar = i.split('.')[0]+'_tar_html.html'\n",
    "    to_drop = [i for i in df1.columns if i not in ['Source','Target','Weight']]\n",
    "    \n",
    "    df1 = pd.read_csv(i).drop(to_drop, axis=1)\n",
    "    df1 = df1.set_index('Source')\n",
    "    df2 = pd.read_csv(i).drop(to_drop, axis=1)\n",
    "    df2 = df2.set_index('Target')\n",
    "    df1 = df1.groupby(\"Source\").sum()\n",
    "    df2 = df2.groupby(\"Target\").sum()\n",
    "    \n",
    "    fig = px.bar(df1['Weight'].nlargest(n=20))\n",
    "    fig.update_xaxes(tickangle = 90)\n",
    "    fig.write_html(path_src)\n",
    "    fig = px.bar(df2['Weight'].nlargest(n=20))\n",
    "    fig.update_xaxes(tickangle = 90)\n",
    "    fig.write_html(path_tar)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f7e022b67859ae4a791bbcc1c75bde8b3a5bef3b9abb0060fdb4399d638fb2f6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
